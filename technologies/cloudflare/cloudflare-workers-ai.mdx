---
title: "Cloudflare Workers AI"
author: "cloudflare"
description: "Run machine learning models, powered by serverless GPUs, on Cloudflare's global network with Workers AI - a serverless AI inference platform for building scalable AI applications at the edge."
---

# Cloudflare Workers AI

Run machine learning models, powered by serverless GPUs, on Cloudflare's global network. Workers AI allows you to run AI models in a serverless way, without having to worry about scaling, maintaining, or paying for unused infrastructure. You can invoke models running on GPUs on Cloudflare's network from your own code â€” from Workers, Pages, or anywhere via the Cloudflare API.

| General     |                                                                  |
| ----------- | ---------------------------------------------------------------- |
| Author      | Cloudflare, Inc.                                                 |
| Website     | [Cloudflare Workers AI](https://www.cloudflare.com/developer-platform/products/workers-ai/) |
| Documentation  | https://developers.cloudflare.com/workers-ai/                   |
| Type        | Serverless AI Inference Platform                                |
| Launch Year | 2023                                                             |
| GPU Network | 180+ cities globally                                             |

## Features

**50+ Open-Source Models**
- Text generation (Llama, Mistral, and more)
- Text embeddings and classification
- Image generation and classification
- Automatic speech recognition
- Translation models
- Object detection capabilities

**Serverless Infrastructure**
- Pay-for-what-you-use pricing model
- Automatic scaling with demand
- No infrastructure management required
- Fast cold start times with V8 isolates

**Global Edge Network**
- AI inference close to users for low latency
- Models available in 180+ cities worldwide
- Reduced network bottlenecks
- Consistent performance globally

**Developer Platform Integration**
- Seamless integration with Cloudflare Workers
- Works with Pages for full-stack AI applications
- REST API for platform-agnostic access
- Integration with Vectorize (vector database)
- AI Gateway for monitoring and control

## Key Capabilities

- **Edge AI Computing**: Run AI models at the network edge for minimal latency
- **Serverless GPU Access**: Access powerful GPU infrastructure without provisioning
- **Model Catalog**: Curated selection of popular open-source AI models
- **Real-time Inference**: Low-latency AI processing for interactive applications
- **Global Deployment**: Deploy once, run everywhere on Cloudflare's network
- **Integrated Ecosystem**: Works with R2 storage, D1 database, and other Cloudflare services

## Use Cases

- Building AI-powered chatbots and conversational interfaces
- Real-time content moderation and classification
- Image and video processing at scale
- Personalization and recommendation engines
- Automated translation and localization
- Voice recognition and text-to-speech applications
- RAG (Retrieval-Augmented Generation) systems
- AI-powered API endpoints and microservices

## Supported Model Categories

- **Large Language Models**: For text generation and chat applications
- **Embedding Models**: For semantic search and similarity matching
- **Image Models**: For generation, classification, and analysis
- **Speech Models**: For transcription and synthesis
- **Vision Models**: For object detection and recognition
- **Translation Models**: For multilingual content processing
